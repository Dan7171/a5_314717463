project: collect_toys
available_parameters_code:
__possibleParameters.push_back(std::make_tuple(0));
__possibleParameters.push_back(std::make_tuple(1));
__possibleParameters.push_back(std::make_tuple(2));
__possibleParameters.push_back(std::make_tuple(3));
__possibleParameters.push_back(std::make_tuple(4));

parameter: int oDestination

dynamic_model:
state__.nav_cnt++;
vector<float> success_chances{0.5, 0.7, 0.8, 0.85, 0.95};
vector<float> accurate_sensor_chances{0.99, 0.7, 0.8, 0.8, 0.95};
float penalty = 0;
bool leaving_self_location = state.robotLocation != oDestination;
bool is_successful_nav = (leaving_self_location && AOS.Bernoulli(success_chances[oDestination])) ? 1: 0;
// penalty of -1 if navigation failed
float nav_penalty = is_successful_nav ? 0: -1;
bool accurate_sensor = AOS.Bernoulli(accurate_sensor_chances[oDestination]);
// real location after action call - moving only if success
state__.robotLocation = is_successful_nav ? oDestination : state.robotLocation;
bool true_success = is_successful_nav && accurate_sensor;
bool false_failure = !is_successful_nav && !accurate_sensor;
__moduleResponse = true_success || false_failure ? eSuccess : eFailed;

// nav total reward
__reward =  -1 + nav_penalty;





