project: collect_toys
horizon: 15
discount: 0.97
#include <random>
// random imported to locate balls and set playtimes

//defining state variables:

// note- next   state variables are constants or debug. I put them here so they can be accessible and shared between scripts (otherwise I need to replace code and its a bad habbit)
state_variable: int baby_loc_const
code:
state.baby_loc_const=4;
state_variable: int hand_loc_const
code:
state.hand_loc_const=5;
state_variable: int action_cnt_dbg
code:
state.action_cnt_dbg=0;
state_variable: int episode_total_rewards_dbg
code:
state.episode_total_rewards_dbg=0;


#include <string>
std::string colors[4] = {"green", "blue", "black", "red"};


// non-constant state variables (the "natural" state variables (natural since state variables shouldn't contain constant values, its a waste of space. Did it only for technical reasons mentions above)
// times navigation action was called
state_variable: int nav_cnt
code:
state.nav_cnt=0;
// times pick action was called
state_variable: int pick_cnt
code:
state.pick_cnt=0;
state_variable: int agentLoc 
code:
state.agentLoc= state.baby_loc_const;
// initialize the ball object:
// for each colored ball, the info we need for the planning is ball loacation (tb inisitalized), reward/ play time (tb initialized) 
define_type: tBall
variable: int location 
variable: float reward 
variable: string color

state_variable: tBall greenBall
code:
state.greenBall.color="green";

state_variable: tBall blueBall
code:
state.blueBall.color="blue";

state_variable: tBall blackBall
code:
state.blackBall.color="black";

state_variable: tBall redBall
code:
state.redBall.color="red";

// define reward codes - for myself - we use goal state also in meaning of terminal state of game over
reward_code:
int max_pick = 6;
int max_nav = 8;
int no_reward = 0;
if(state.pick_cnt > max_pick || state.nav_cnt > max_nav)
{
	__isGoalState =true;
	__reward= no_reward;
}

// run on the 4 ball objects (for self I think adding Objects to the end of the type name is somehow making it a list)
bool all_placed = (state.greenBall.location == 4 && state.blueBall.location == 4 && state.blackBall.location == 4 && state.redBall.location == 4);
if (all_placed){
    __isGoalState =true;
	__reward=no_reward;
}


// in initial belief  - randomly sample locations and playtimes for each ball 
initial_belief:

//initialize *locations*

std::random_device rd;
std::mt19937 gen(rd());
vector<float> green_loc_w{0.1,0.05,0.8,0.05};
vector<float> blue_loc_w{0.7,0.1,0.1,0.1};
vector<float> black_loc_w{0,0,0,0};

// green
std::discrete_distribution<> loc_dist_green(green_loc_w.begin(), green_loc_w.end());
int selected_loc_green = loc_dist_green(gen);
state.greenBall.location =  selected_loc_green;

//blue
float compensation = blue_loc_w[selected_loc_green]/3;
for(int i=0;i<4;i++){
	if(i == selected_loc_green){
		blue_loc_w[i]=0;
	}
	else{
		blue_loc_w[i]+= compensation;
	}
}

std::discrete_distribution<> loc_dist_blue(blue_loc_w.begin(), blue_loc_w.end());
int selected_loc_blue= loc_dist_blue(gen);
state.blueBall.location =  selected_loc_blue;

// black
for(int i=0;i<4;i++){
	if (!(i == selected_loc_green || i == selected_loc_blue)){
		black_loc_w[i]=0.5;
	}
}
std::discrete_distribution<> loc_dist_black(black_loc_w.begin(), black_loc_w.end());
int selected_loc_black= loc_dist_black(gen);
state.blackBall.location =  selected_loc_black;

// red - takes the last location left 
for(int i=0;i<4;i++){
	if (!(i == selected_loc_green || i == selected_loc_blue || i == selected_loc_black)){
		int selected_loc_red = i;
		state.redBall.location = selected_loc_red ;
	}
}

//initialize *playtimes* (rewards)

//set playtime selection chance for each ball (playtime is the reward)
vector<float> rewards{40,20,15,15};
vector<float> green_pt_w{0.8,0.05,0.1,0.05};
vector<float> blue_pt_w{0.1,0.7,0.1,0.1};
vector<float> black_pt_w{0,0,0,0};

// green
std::discrete_distribution<> pt_dist_green(green_pt_w.begin(), green_pt_w.end());
int selected_pt_idx_green= pt_dist_green(gen);
state.greenBall.reward=  rewards[selected_pt_idx_green];

//blue
compensation = blue_pt_w[selected_pt_idx_green]/3;
for(int i=0;i<4;i++){
	if(i == selected_pt_idx_green){
		blue_pt_w[i]=0;
	}
	else{
		blue_pt_w[i]+= compensation;
	}
}

std::discrete_distribution<> pt_dist_blue(blue_pt_w.begin(), blue_pt_w.end());
int selected_pt_idx_blue= pt_dist_blue(gen);
state.blueBall.reward=  rewards[selected_pt_idx_blue];
        
// black
for(int i=0;i<4;i++){
	if (!(i == selected_pt_idx_green || i == selected_pt_idx_blue)){
		black_pt_w[i]=0.5;
	}
}
std::discrete_distribution<> pt_dist_black(black_pt_w.begin(), black_pt_w.end());
int selected_pt_idx_black= pt_dist_black(gen);
state.blackBall.reward =  rewards[selected_pt_idx_black];

// red
// red - takes what left (as before)
for(int i=0;i<4;i++){
	if (!(i == selected_pt_idx_green || i == selected_pt_idx_blue || i == selected_pt_idx_black)){
		int selected_pt_idx_red = i;
		state.redBall.reward= rewards[selected_pt_idx_red] ;
	}
}


